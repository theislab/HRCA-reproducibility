['00_6_run_GPU_methods.py', '6']
pytorch + cuda
1.8.0
2.7.0
scgen
# of detected devices 2
0 /device:CPU:0
1 /device:GPU:0
query 6
method                                         scanvi_E100_L3_H256
hvg                                                           3000
cell_type_key                                                  NaN
input            /lustre/groups/ml01/workspace/ignacio.ibarra/t...
output           /lustre/groups/ml01/workspace/ignacio.ibarra/t...
nepochs                                                      100.0
nlayers                                                        3.0
nhidden                                                      256.0
Name: 6, dtype: object
# epochs 100.0
True /lustre/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_cells_Chenfixed+Hackney_batch_donor_dataset_cell.type/prepare/unscaled/HVG.3K/adata_pre.h5ad
False /lustre/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_cells_Chenfixed+Hackney_batch_donor_dataset_cell.type/integration/unscaled/HVG.3K/scanvi_E100_L3_H256.h5ad

False /lustre/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_cells_Chenfixed+Hackney_batch_donor_dataset_cell.type/integration/unscaled/HVG.3K/scanvi_E100_L3_H256_embed.csv
reading input...
location of scripts...
<module 'scIB.integration' from '/home/icb/ignacio.ibarra/miniconda3/envs/scIB-python/lib/python3.7/site-packages/scIB/integration.py'>
(568985, 3000)
scanvi
[34mINFO    [0m Remapping labels to [1m[[0m[1;36m0[0m,N[1m][0m                                              
[34mINFO    [0m Remapping batch_indices to [1m[[0m[1;36m0[0m,N[1m][0m                                       
[34mINFO    [0m Computing the library size for the new data                            
[34mINFO    [0m Downsampled from [1;36m568985[0m to [1;36m568985[0m cells                                
scANVI dataset object with 46 batches and 11 cell types
# epochs scVI 100
# epochs scANVI 10
# layers 3
# hidden 256
[34mINFO    [0m KL warmup phase exceeds overall training phaseIf your applications rely
         on the posterior quality, consider training for more epochs or reducing
         the kl warmup.                                                         
[34mINFO    [0m KL warmup for [1;36m400[0m epochs                                               
training:   0%|          | 0/100 [00:00<?, ?it/s]training:   1%|          | 1/100 [05:53<9:43:24, 353.58s/it]training:   2%|â–         | 2/100 [11:48<9:39:15, 354.65s/it]training:   3%|â–Ž         | 3/100 [17:43<9:33:25, 354.70s/it]training:   4%|â–         | 4/100 [23:45<9:31:52, 357.42s/it]training:   5%|â–Œ         | 5/100 [29:44<9:27:02, 358.13s/it]training:   6%|â–Œ         | 6/100 [35:44<9:21:42, 358.54s/it]training:   7%|â–‹         | 7/100 [41:40<9:14:54, 358.01s/it]training:   8%|â–Š         | 8/100 [47:35<9:07:09, 356.85s/it]training:   9%|â–‰         | 9/100 [53:30<9:00:16, 356.23s/it]training:  10%|â–ˆ         | 10/100 [59:24<8:53:22, 355.58s/it]training:  11%|â–ˆ         | 11/100 [1:05:15<8:45:24, 354.21s/it]training:  12%|â–ˆâ–        | 12/100 [1:11:09<8:39:21, 354.11s/it]training:  13%|â–ˆâ–Ž        | 13/100 [1:17:09<8:36:09, 355.97s/it]training:  14%|â–ˆâ–        | 14/100 [1:23:04<8:29:40, 355.59s/it]training:  15%|â–ˆâ–Œ        | 15/100 [1:29:10<8:28:14, 358.76s/it]training:  16%|â–ˆâ–Œ        | 16/100 [1:35:10<8:22:38, 359.03s/it]training:  17%|â–ˆâ–‹        | 17/100 [1:41:04<8:14:56, 357.79s/it]training:  18%|â–ˆâ–Š        | 18/100 [1:46:57<8:06:37, 356.07s/it]training:  19%|â–ˆâ–‰        | 19/100 [1:52:48<7:58:44, 354.62s/it]training:  20%|â–ˆâ–ˆ        | 20/100 [1:58:49<7:55:40, 356.76s/it]training:  21%|â–ˆâ–ˆ        | 21/100 [2:04:46<7:49:28, 356.56s/it]training:  22%|â–ˆâ–ˆâ–       | 22/100 [2:10:48<7:45:55, 358.40s/it]training:  23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:16:39<7:36:50, 355.99s/it]training:  24%|â–ˆâ–ˆâ–       | 24/100 [2:22:39<7:32:25, 357.18s/it]training:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:28:36<7:26:24, 357.12s/it]training:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:34:35<7:21:10, 357.71s/it]training:  27%|â–ˆâ–ˆâ–‹       | 27/100 [2:40:30<7:14:20, 356.99s/it]training:  28%|â–ˆâ–ˆâ–Š       | 28/100 [2:46:25<7:07:46, 356.48s/it]training:  29%|â–ˆâ–ˆâ–‰       | 29/100 [2:52:21<7:01:41, 356.36s/it]training:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:58:15<6:54:42, 355.46s/it]training:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:04:09<6:48:12, 354.97s/it]training:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:10:02<6:41:37, 354.37s/it]training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:16:09<6:39:56, 358.16s/it]training:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:22:06<6:33:40, 357.88s/it]training:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:27:57<6:25:34, 355.92s/it]training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:33:54<6:20:01, 356.27s/it]training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:39:46<6:12:33, 354.81s/it]training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:45:46<6:08:26, 356.55s/it]training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:51:44<6:02:52, 356.93s/it]training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:57:33<5:54:26, 354.45s/it]training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:03:30<5:49:19, 355.24s/it]training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:09:27<5:44:04, 355.93s/it]training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:15:28<5:39:34, 357.45s/it]training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:21:18<5:31:34, 355.27s/it]training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:27:15<5:25:58, 355.61s/it]training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:33:15<5:21:18, 357.02s/it]training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:39:06<5:13:45, 355.20s/it]training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:45:01<5:07:45, 355.10s/it]training:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:50:53<5:01:07, 354.27s/it]training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:56:52<4:56:23, 355.66s/it]training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:02:45<4:49:50, 354.92s/it]training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:08:41<4:44:09, 355.20s/it]training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:14:39<4:38:43, 355.81s/it]training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:20:38<4:33:35, 356.86s/it]training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:26:35<4:27:46, 357.03s/it]training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:32:31<4:21:36, 356.75s/it]training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:38:25<4:15:05, 355.93s/it]training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:44:24<4:09:39, 356.66s/it]training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:50:18<4:03:09, 355.84s/it]training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:56:16<3:57:37, 356.44s/it]training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:02:08<3:50:54, 355.25s/it]training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:08:02<3:44:43, 354.84s/it]training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:14:00<3:39:30, 355.97s/it]training:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:19:58<3:33:47, 356.33s/it]training:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [6:25:52<3:27:30, 355.74s/it]training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [6:31:45<3:21:02, 354.78s/it]training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:37:41<3:15:20, 355.18s/it]training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:43:41<3:10:14, 356.71s/it]training:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:49:36<3:03:58, 356.09s/it]training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:55:33<2:58:13, 356.45s/it]training:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:01:28<2:52:07, 356.13s/it]training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:07:25<2:46:20, 356.45s/it]training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:13:19<2:39:56, 355.44s/it]training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [7:19:13<2:33:57, 355.29s/it]training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [7:25:07<2:27:49, 354.77s/it]training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [7:31:00<2:21:39, 354.14s/it]training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [7:36:52<2:15:34, 353.67s/it]training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [7:42:40<2:09:02, 351.95s/it]training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:48:34<2:03:19, 352.36s/it]training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:54:26<1:57:26, 352.34s/it]training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:00:15<1:51:13, 351.25s/it]training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:06:08<1:45:35, 351.95s/it]training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [8:12:03<1:39:55, 352.68s/it]training:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [8:17:57<1:34:10, 353.16s/it]training:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [8:23:52<1:28:26, 353.73s/it]training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [8:29:45<1:22:30, 353.58s/it]training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [8:35:38<1:16:32, 353.28s/it]training:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [8:41:33<1:10:46, 353.91s/it]training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [8:47:24<1:04:43, 353.05s/it]training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:53:10<58:30, 351.05s/it]  training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [8:59:01<52:38, 350.92s/it]training:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:04:52<46:47, 350.98s/it]training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [9:10:42<40:53, 350.54s/it]training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [9:16:28<34:54, 349.13s/it]training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [9:22:09<28:53, 346.70s/it]training:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [9:27:54<23:05, 346.31s/it]training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [9:33:44<17:21, 347.29s/it]training:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [9:39:35<11:37, 348.50s/it]training:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [9:45:26<05:49, 349.15s/it]training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:51:06<00:00, 346.40s/it]training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:51:06<00:00, 354.66s/it]
[34mINFO    [0m Training is still in warming up phase. If your applications rely on the
         posterior quality, consider training for more epochs or reducing the kl
         warmup.                                                                
[34mINFO    [0m KL warmup phase exceeds overall training phaseIf your applications rely
         on the posterior quality, consider training for more epochs or reducing
         the kl warmup.                                                         
[34mINFO    [0m KL warmup for [1;36m400[0m epochs                                               
training:   0%|          | 0/10 [00:00<?, ?it/s]training:  10%|â–ˆ         | 1/10 [02:54<26:09, 174.34s/it]training:  20%|â–ˆâ–ˆ        | 2/10 [05:46<23:06, 173.32s/it]training:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [08:39<20:10, 172.95s/it]training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [11:32<17:18, 173.15s/it]training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [14:29<14:32, 174.40s/it]training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [17:27<11:42, 175.51s/it]training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [20:21<08:45, 175.15s/it]training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [23:15<05:49, 174.66s/it]training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [26:11<02:55, 175.09s/it]training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [29:07<00:00, 175.59s/it]training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [29:07<00:00, 174.80s/it]
[34mINFO    [0m Training is still in warming up phase. If your applications rely on the
         posterior quality, consider training for more epochs or reducing the kl
         warmup.                                                                
about to write to output scANVI...
