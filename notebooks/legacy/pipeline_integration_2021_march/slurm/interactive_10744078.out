['00_6_run_GPU_methods.py', '9']
pytorch + cuda
1.8.0
2.7.0
scgen
# of detected devices 2
0 /device:CPU:0
1 /device:GPU:0
query 9
method                                                   scvi_E100
hvg                                                           3000
cell_type_key                                                  NaN
input            /lustre/groups/ml01/workspace/ignacio.ibarra/t...
output           /lustre/groups/ml01/workspace/ignacio.ibarra/t...
nepochs                                                      100.0
nlayers                                                        NaN
nhidden                                                        NaN
Name: 9, dtype: object
# epochs 100.0
True /lustre/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_cells_Chenfixed+Hackney_batch_donor_dataset_cell.type/prepare/unscaled/HVG.3K/adata_pre.h5ad
False /lustre/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_cells_Chenfixed+Hackney_batch_donor_dataset_cell.type/integration/unscaled/HVG.3K/scvi_E100.h5ad

False /lustre/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_cells_Chenfixed+Hackney_batch_donor_dataset_cell.type/integration/unscaled/HVG.3K/scvi_E100_embed.csv
reading input...
location of scripts...
<module 'scIB.integration' from '/home/icb/ignacio.ibarra/miniconda3/envs/scIB-python/lib/python3.7/site-packages/scIB/integration.py'>
(568985, 3000)
scVI...
# of epochs (estimated or user): 100
[34mINFO    [0m Remapping batch_indices to [1m[[0m[1;36m0[0m,N[1m][0m                                       
[34mINFO    [0m Remapping labels to [1m[[0m[1;36m0[0m,N[1m][0m                                              
[34mINFO    [0m Computing the library size for the new data                            
[34mINFO    [0m Downsampled from [1;36m568985[0m to [1;36m568985[0m cells                                
Train size 1.0
[34mINFO    [0m KL warmup phase exceeds overall training phaseIf your applications rely
         on the posterior quality, consider training for more epochs or reducing
         the kl warmup.                                                         
[34mINFO    [0m KL warmup for [1;36m400[0m epochs                                               
training:   0%|          | 0/100 [00:00<?, ?it/s]training:   1%|          | 1/100 [05:49<9:37:20, 349.90s/it]training:   2%|▏         | 2/100 [11:43<9:35:04, 352.09s/it]training:   3%|▎         | 3/100 [17:39<9:31:54, 353.76s/it]training:   4%|▍         | 4/100 [23:35<9:27:18, 354.56s/it]training:   5%|▌         | 5/100 [29:28<9:20:57, 354.29s/it]training:   6%|▌         | 6/100 [35:21<9:13:55, 353.57s/it]training:   7%|▋         | 7/100 [41:14<9:07:51, 353.45s/it]training:   8%|▊         | 8/100 [47:01<8:58:50, 351.42s/it]training:   9%|▉         | 9/100 [52:49<8:51:22, 350.35s/it]training:  10%|█         | 10/100 [58:35<8:43:40, 349.11s/it]training:  11%|█         | 11/100 [1:04:29<8:39:56, 350.52s/it]training:  12%|█▏        | 12/100 [1:10:15<8:32:17, 349.29s/it]training:  13%|█▎        | 13/100 [1:16:07<8:27:27, 349.97s/it]training:  14%|█▍        | 14/100 [1:21:59<8:22:22, 350.50s/it]training:  15%|█▌        | 15/100 [1:27:49<8:16:19, 350.35s/it]training:  16%|█▌        | 16/100 [1:33:36<8:09:10, 349.41s/it]training:  17%|█▋        | 17/100 [1:39:31<8:05:38, 351.06s/it]training:  18%|█▊        | 18/100 [1:45:24<8:00:51, 351.85s/it]training:  19%|█▉        | 19/100 [1:51:15<7:54:34, 351.54s/it]training:  20%|██        | 20/100 [1:57:05<7:48:01, 351.02s/it]training:  21%|██        | 21/100 [2:02:56<7:42:17, 351.11s/it]training:  22%|██▏       | 22/100 [2:08:45<7:35:22, 350.29s/it]training:  23%|██▎       | 23/100 [2:14:35<7:29:31, 350.28s/it]training:  24%|██▍       | 24/100 [2:20:31<7:25:54, 352.04s/it]training:  25%|██▌       | 25/100 [2:26:27<7:21:36, 353.28s/it]training:  26%|██▌       | 26/100 [2:32:19<7:15:00, 352.71s/it]training:  27%|██▋       | 27/100 [2:38:08<7:07:56, 351.74s/it]training:  28%|██▊       | 28/100 [2:44:01<7:02:38, 352.20s/it]training:  29%|██▉       | 29/100 [2:49:54<6:56:51, 352.27s/it]training:  30%|███       | 30/100 [2:55:48<6:51:27, 352.68s/it]training:  31%|███       | 31/100 [3:01:45<6:47:06, 354.00s/it]training:  32%|███▏      | 32/100 [3:07:33<6:39:11, 352.22s/it]training:  33%|███▎      | 33/100 [3:13:23<6:32:36, 351.58s/it]training:  34%|███▍      | 34/100 [3:19:16<6:27:24, 352.19s/it]training:  35%|███▌      | 35/100 [3:25:09<6:21:38, 352.28s/it]training:  36%|███▌      | 36/100 [3:31:02<6:16:11, 352.67s/it]training:  37%|███▋      | 37/100 [3:36:52<6:09:19, 351.74s/it]training:  38%|███▊      | 38/100 [3:42:46<6:04:04, 352.33s/it]training:  39%|███▉      | 39/100 [3:48:37<5:57:47, 351.92s/it]training:  40%|████      | 40/100 [3:54:29<5:51:53, 351.90s/it]training:  41%|████      | 41/100 [4:00:17<5:45:08, 350.99s/it]training:  42%|████▏     | 42/100 [4:06:11<5:40:06, 351.83s/it]training:  43%|████▎     | 43/100 [4:11:59<5:33:09, 350.69s/it]training:  44%|████▍     | 44/100 [4:17:45<5:25:52, 349.16s/it]training:  45%|████▌     | 45/100 [4:23:37<5:20:54, 350.08s/it]training:  46%|████▌     | 46/100 [4:29:31<5:16:04, 351.20s/it]training:  47%|████▋     | 47/100 [4:35:25<5:10:58, 352.05s/it]training:  48%|████▊     | 48/100 [4:41:17<5:05:09, 352.11s/it]training:  49%|████▉     | 49/100 [4:47:09<4:59:09, 351.94s/it]training:  50%|█████     | 50/100 [4:53:00<4:53:02, 351.65s/it]training:  51%|█████     | 51/100 [4:58:47<4:46:04, 350.29s/it]training:  52%|█████▏    | 52/100 [5:04:34<4:39:27, 349.33s/it]training:  53%|█████▎    | 53/100 [5:10:23<4:33:32, 349.20s/it]training:  54%|█████▍    | 54/100 [5:16:13<4:27:59, 349.56s/it]training:  55%|█████▌    | 55/100 [5:22:02<4:22:00, 349.35s/it]training:  56%|█████▌    | 56/100 [5:27:53<4:16:31, 349.81s/it]training:  57%|█████▋    | 57/100 [5:33:49<4:11:59, 351.61s/it]training:  58%|█████▊    | 58/100 [5:39:37<4:05:19, 350.47s/it]training:  59%|█████▉    | 59/100 [5:45:25<3:59:10, 350.02s/it]training:  60%|██████    | 60/100 [5:51:16<3:53:29, 350.25s/it]training:  61%|██████    | 61/100 [5:57:12<3:48:48, 352.00s/it]training:  62%|██████▏   | 62/100 [6:03:04<3:42:50, 351.85s/it]training:  63%|██████▎   | 63/100 [6:08:54<3:36:44, 351.46s/it]training:  64%|██████▍   | 64/100 [6:14:43<3:30:20, 350.57s/it]training:  65%|██████▌   | 65/100 [6:20:32<3:24:16, 350.17s/it]training:  66%|██████▌   | 66/100 [6:26:25<3:18:50, 350.91s/it]training:  67%|██████▋   | 67/100 [6:32:16<3:13:00, 350.94s/it]training:  68%|██████▊   | 68/100 [6:38:03<3:06:38, 349.94s/it]training:  69%|██████▉   | 69/100 [6:43:52<3:00:39, 349.65s/it]training:  70%|███████   | 70/100 [6:49:42<2:54:45, 349.50s/it]training:  71%|███████   | 71/100 [6:55:35<2:49:31, 350.75s/it]training:  72%|███████▏  | 72/100 [7:01:25<2:43:32, 350.46s/it]training:  73%|███████▎  | 73/100 [7:07:19<2:38:12, 351.57s/it]training:  74%|███████▍  | 74/100 [7:13:06<2:31:41, 350.04s/it]training:  75%|███████▌  | 75/100 [7:18:55<2:25:46, 349.85s/it]training:  76%|███████▌  | 76/100 [7:24:47<2:20:12, 350.52s/it]training:  77%|███████▋  | 77/100 [7:30:33<2:13:47, 349.02s/it]training:  78%|███████▊  | 78/100 [7:36:19<2:07:38, 348.13s/it]training:  79%|███████▉  | 79/100 [7:42:08<2:01:56, 348.39s/it]training:  80%|████████  | 80/100 [7:48:00<1:56:33, 349.70s/it]training:  81%|████████  | 81/100 [7:53:46<1:50:19, 348.40s/it]training:  82%|████████▏ | 82/100 [7:59:34<1:44:29, 348.33s/it]training:  83%|████████▎ | 83/100 [8:05:18<1:38:20, 347.07s/it]training:  84%|████████▍ | 84/100 [8:11:03<1:32:22, 346.40s/it]training:  85%|████████▌ | 85/100 [8:16:53<1:26:53, 347.57s/it]training:  86%|████████▌ | 86/100 [8:22:42<1:21:09, 347.84s/it]training:  87%|████████▋ | 87/100 [8:28:27<1:15:13, 347.16s/it]training:  88%|████████▊ | 88/100 [8:34:15<1:09:27, 347.27s/it]training:  89%|████████▉ | 89/100 [8:40:06<1:03:51, 348.35s/it]training:  90%|█████████ | 90/100 [8:45:48<57:46, 346.67s/it]  training:  91%|█████████ | 91/100 [8:51:30<51:45, 345.05s/it]training:  92%|█████████▏| 92/100 [8:57:13<45:55, 344.43s/it]training:  93%|█████████▎| 93/100 [9:02:56<40:09, 344.23s/it]training:  94%|█████████▍| 94/100 [9:08:39<34:22, 343.74s/it]training:  95%|█████████▌| 95/100 [9:14:20<28:34, 342.92s/it]training:  96%|█████████▌| 96/100 [9:19:59<22:46, 341.65s/it]training:  97%|█████████▋| 97/100 [9:25:42<17:06, 342.26s/it]training:  98%|█████████▊| 98/100 [9:31:25<11:24, 342.31s/it]training:  99%|█████████▉| 99/100 [9:37:09<05:42, 342.91s/it]training: 100%|██████████| 100/100 [9:42:57<00:00, 344.29s/it]training: 100%|██████████| 100/100 [9:42:57<00:00, 349.77s/it]
[34mINFO    [0m Training is still in warming up phase. If your applications rely on the
         posterior quality, consider training for more epochs or reducing the kl
         warmup.                                                                
