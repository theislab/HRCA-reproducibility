{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import scanpy as sc\n",
    "import scIB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-l', '--seurat'], dest='seurat', nargs=0, const=True, default=False, type=None, choices=None, help='Generate output for seurat including hvg list', metavar=None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run the integration methods')\n",
    "\n",
    "parser.add_argument('-i', '--input_file', required=True)\n",
    "parser.add_argument('-o', '--output_file', required=True)\n",
    "parser.add_argument('-b', '--batch', required=True, help='Batch variable')\n",
    "parser.add_argument('-v', '--hvgs', help='Number of highly variable genes', default=2000)\n",
    "parser.add_argument('-r', '--rout', help='Save output for R methods', action='store_true')\n",
    "parser.add_argument('-s', '--scale', action='store_true', help='Scale the data per batch')\n",
    "parser.add_argument('-l', '--seurat', help='Generate output for seurat including hvg list', action='store_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '''-i /storage/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/input/input_500_cells_Chen+Hackney.h5ad -o /storage/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/output/retinal_all_Chen+Hackney_batch_donor_dataset_cell.type/prepare/unscaled/HVG.1K/adata_pre.RDS -b batch_donor_dataset --hvgs 1000 -r -l'''\n",
    "# input_h5ad = '/storage/groups/ml01/workspace/ignacio.ibarra/theislab/retinal_scRNAseq_integration/data/integration_march_2021/input/input_all_cells_Chen+Hackney.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=cmd.split(' '))\n",
    "args\n",
    "file = args.input_file\n",
    "out = args.output_file\n",
    "batch = args.batch\n",
    "hvg = int(args.hvgs)\n",
    "rout = args.rout\n",
    "seurat = args.seurat\n",
    "scale = args.scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = file\n",
    "outPath = out\n",
    "hvg = hvg\n",
    "batch = batch\n",
    "rout = rout\n",
    "seurat = seurat\n",
    "scale = scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "params:\n",
    "    inPath: path of the anndata object\n",
    "    outPath: path of the preprocessed file to be written\n",
    "    hvg: number of highly variable genes to use\n",
    "    rout: set to true to save a Seurat object\n",
    "    scale: set to true to activate scaling\n",
    "    seurat: set to true to produce hvg list\n",
    "\"\"\"\n",
    "\n",
    "adata = sc.read(inPath)\n",
    "hvgs=adata.var.index\n",
    "\n",
    "\n",
    "# print(adata.X.has_sorted_indices)\n",
    "# adata.X.sort_indices()\n",
    "# print(adata.X.has_sorted_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing HVGs ...\n",
      "Using 6 HVGs from full intersect set\n",
      "Using 8 HVGs from n_batch-1 set\n",
      "Using 19 HVGs from n_batch-2 set\n",
      "Using 20 HVGs from n_batch-3 set\n",
      "Using 25 HVGs from n_batch-4 set\n",
      "Using 40 HVGs from n_batch-5 set\n",
      "Using 32 HVGs from n_batch-6 set\n",
      "Using 16 HVGs from n_batch-7 set\n",
      "Using 28 HVGs from n_batch-8 set\n",
      "Using 17 HVGs from n_batch-9 set\n",
      "Using 22 HVGs from n_batch-10 set\n",
      "Using 19 HVGs from n_batch-11 set\n",
      "Using 22 HVGs from n_batch-12 set\n",
      "Using 14 HVGs from n_batch-13 set\n",
      "Using 17 HVGs from n_batch-14 set\n",
      "Using 14 HVGs from n_batch-15 set\n",
      "Using 17 HVGs from n_batch-16 set\n",
      "Using 15 HVGs from n_batch-17 set\n",
      "Using 17 HVGs from n_batch-18 set\n",
      "Using 17 HVGs from n_batch-19 set\n",
      "Using 15 HVGs from n_batch-20 set\n",
      "Using 12 HVGs from n_batch-21 set\n",
      "Using 22 HVGs from n_batch-22 set\n",
      "Using 19 HVGs from n_batch-23 set\n",
      "Using 10 HVGs from n_batch-24 set\n",
      "Using 15 HVGs from n_batch-25 set\n",
      "Using 20 HVGs from n_batch-26 set\n",
      "Using 17 HVGs from n_batch-27 set\n",
      "Using 19 HVGs from n_batch-28 set\n",
      "Using 9 HVGs from n_batch-29 set\n",
      "Using 18 HVGs from n_batch-30 set\n",
      "Using 10 HVGs from n_batch-31 set\n",
      "Using 10 HVGs from n_batch-32 set\n",
      "Using 13 HVGs from n_batch-33 set\n",
      "Using 17 HVGs from n_batch-34 set\n",
      "Using 12 HVGs from n_batch-35 set\n",
      "Using 17 HVGs from n_batch-36 set\n",
      "Using 15 HVGs from n_batch-37 set\n",
      "Using 10 HVGs from n_batch-38 set\n",
      "Using 15 HVGs from n_batch-39 set\n",
      "Using 17 HVGs from n_batch-40 set\n",
      "Using 20 HVGs from n_batch-41 set\n",
      "Using 18 HVGs from n_batch-42 set\n",
      "Using 22 HVGs from n_batch-43 set\n",
      "Using 10 HVGs from n_batch-44 set\n",
      "Using 18 HVGs from n_batch-45 set\n",
      "Using 24 HVGs from n_batch-46 set\n",
      "Using 18 HVGs from n_batch-47 set\n",
      "Using 20 HVGs from n_batch-48 set\n",
      "Using 21 HVGs from n_batch-49 set\n",
      "Using 26 HVGs from n_batch-50 set\n",
      "Using 12 HVGs from n_batch-51 set\n",
      "Using 23 HVGs from n_batch-52 set\n",
      "Using 21 HVGs from n_batch-53 set\n",
      "Using 20 HVGs from n_batch-54 set\n",
      "Using 21 HVGs from n_batch-55 set\n",
      "Using 9 HVGs from n_batch-56 set\n",
      "Using 1000 HVGs\n",
      "done with computing HVGs\n",
      "adata\n",
      "AnnData object with n_obs × n_vars = 42998 × 12180\n",
      "    obs: 'RNA_snn_res.0.8', 'batch', 'dataset', 'filename', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'scpred_AC', 'scpred_Astrocyte', 'scpred_BC', 'scpred_Cone', 'scpred_HC', 'scpred_MG', 'scpred_Microglia', 'scpred_RGC', 'scpred_RPE', 'scpred_Rod', 'scpred_max', 'scpred_prediction', 'seurat_clusters', 'size_factors', 'cell.type', 'batch.merged', 'donor', 'batch_donor_dataset'\n",
      "    layers: 'counts'\n",
      "var\n",
      "Index([], dtype='object')\n",
      "hvgs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# hvgs_bkp = adata.var['highly_variable']\n",
    "# remove HVG if already precomputed\n",
    "if 'highly_variable' in adata.var:\n",
    "    del adata.var['highly_variable']\n",
    "\n",
    "if hvg > 500:\n",
    "    print(\"Computing HVGs ...\")\n",
    "    if seurat:\n",
    "        hvgs= scIB.preprocessing.hvg_batch(adata,batch_key=batch, target_genes=hvg, adataOut=False)\n",
    "    else:\n",
    "        adata = scIB.preprocessing.hvg_batch(adata,\n",
    "                                            batch_key=batch,\n",
    "                                            target_genes=hvg,\n",
    "                                            adataOut=True)\n",
    "    print('done with computing HVGs')\n",
    "    print('adata')\n",
    "    print(adata)\n",
    "    print('var')\n",
    "    print(adata.var.columns)\n",
    "    print('hvgs')\n",
    "    # print(hvgs)\n",
    "\n",
    "if scale:\n",
    "    print(\"Scaling data ...\")\n",
    "    adata = scIB.preprocessing.scale_batch(adata, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anndata._core.views.SparseCSRView"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adata_hvg.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'anndata._core.views.SparseCSRView'>\n"
     ]
    }
   ],
   "source": [
    "(type(adata_hvg.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 42998 × 12180\n",
       "    obs: 'RNA_snn_res.0.8', 'batch', 'dataset', 'filename', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'scpred_AC', 'scpred_Astrocyte', 'scpred_BC', 'scpred_Cone', 'scpred_HC', 'scpred_MG', 'scpred_Microglia', 'scpred_RGC', 'scpred_RPE', 'scpred_Rod', 'scpred_max', 'scpred_prediction', 'seurat_clusters', 'size_factors', 'cell.type', 'batch.merged', 'donor', 'batch_donor_dataset'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save as RDS\n",
      "remove counts as maybe no necessary for R methods...\n",
      "has sorted indexes? 1\n",
      "are there duplicates? TCAGTGACAGGACGAT-1_2-28:Chen_a:28    1\n",
      "CTACTATGTTCCCAAA-1-29:Chen_a:29      1\n",
      "TCCATCGGTATCTCGA-1-7:Chen_b:7        1\n",
      "CCACGTTCAGAGATGC-1-6:Chen_c:6        1\n",
      "GCATCTCGTATGCGGA-1-22:Chen_a:22      1\n",
      "                                    ..\n",
      "CACAGGCAGGTACAAT-1-0:Chen_c:0        1\n",
      "CELL3944749-7:Hackney:7              1\n",
      "GTAACACTCACAAGGG-1-9:Chen_b:9        1\n",
      "TACCCACTCATCGCTC-1-4:Chen_a:4        1\n",
      "TCTTCCTTCCCTTGGT-1-10:Chen_b:10      1\n",
      "Length: 42998, dtype: int64\n",
      "has sorted indexes (after sorting)? 1\n",
      "info before writing\n",
      "View of AnnData object with n_obs × n_vars = 42998 × 1000\n",
      "    obs: 'RNA_snn_res.0.8', 'batch', 'dataset', 'filename', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'scpred_AC', 'scpred_Astrocyte', 'scpred_BC', 'scpred_Cone', 'scpred_HC', 'scpred_MG', 'scpred_Microglia', 'scpred_RGC', 'scpred_RPE', 'scpred_Rod', 'scpred_max', 'scpred_prediction', 'seurat_clusters', 'size_factors', 'cell.type', 'batch.merged', 'donor', 'batch_donor_dataset'\n",
      "    layers: 'counts'\n",
      "(42998, 1000)\n",
      "has raw None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if rout:\n",
    "    print(\"Save as RDS\")\n",
    "    # attempt to remove counts for Seurat/Conos/Harmony\n",
    "    import gc\n",
    "    print('remove counts as maybe no necessary for R methods...')\n",
    "    \n",
    "    # do not remove counts\n",
    "    # if 'counts' in adata.layers:\n",
    "    #     del adata.layers['counts']\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    adata_hvg = adata[:,adata.var.index.isin(hvgs)]\n",
    "\n",
    "    print('has sorted indexes?', adata_hvg.X.has_sorted_indices)\n",
    "    # print('sorting indexes...')\n",
    "    # adata_hvg.X.sort_indices()\n",
    "\n",
    "    print('are there duplicates?', adata_hvg.obs_names.value_counts())\n",
    "    print('has sorted indexes (after sorting)?', adata_hvg.X.has_sorted_indices)\n",
    "\n",
    "    print('info before writing')\n",
    "    print(adata_hvg)\n",
    "    print(adata_hvg.shape)\n",
    "    # print(adata.X)\n",
    "    print('has raw', adata_hvg.raw)\n",
    "    adata_hvg = adata_hvg.copy()\n",
    "    \n",
    "    scIB.preprocessing.saveSeurat(adata_hvg, outPath, batch, hvgs)\n",
    "    # scIB.preprocessing.saveSeurat(adata, outPath, batch, hvgs)\n",
    "\n",
    "else:\n",
    "    print(\"Save as HDF5\")\n",
    "    sc.write(outPath, adata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scIB-python]",
   "language": "python",
   "name": "conda-env-scIB-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
